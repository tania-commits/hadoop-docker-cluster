# ClÃºster Hadoop con Docker

Este repositorio contiene un clÃºster Hadoop pseudo-distribuido usando **Docker** y **Docker Compose**. Incluye:

* `Dockerfile` para construir la imagen de Hadoop.
* `docker-compose.yml` para levantar los servicios NameNode, DataNode, ResourceManager y NodeManager.
* Carpeta `conf/` con la configuraciÃ³n XML de Hadoop (`core-site.xml`, `hdfs-site.xml`, `mapred-site.xml`, `yarn-site.xml`).
* Script `start-dfs.sh` para inicializar el NameNode.

---

## Requisitos

* Docker y Docker Compose instalados en tu mÃ¡quina.
* Sistema operativo compatible (Linux, Windows con WSL2 o MacOS).
* Git para clonar o actualizar el repositorio.

---

## ConstrucciÃ³n de la imagen

En la raÃ­z del proyecto:

```bash
docker build -t myhadoop:3.4.2 .
```

Esto crearÃ¡ la imagen `myhadoop:3.4.2` con Hadoop instalado y configurado.

---

## Levantar el clÃºster

Usando Docker Compose:

```bash
docker-compose up -d
```

Esto arrancarÃ¡ los contenedores:

* `namenode` â†’ HDFS NameNode
* `datanode` â†’ HDFS DataNode
* `resourcemanager` â†’ YARN ResourceManager
* `nodemanager` â†’ YARN NodeManager

---

## Comprobar servicios

* **Interface web del NameNode:** [http://localhost:9870](http://localhost:9870)
* **Interface web del ResourceManager:** [http://localhost:8088](http://localhost:8088)

---

## Comandos bÃ¡sicos dentro del NameNode

Para acceder al contenedor del NameNode:

```bash
docker exec -it namenode bash
```

Dentro del contenedor, puedes probar HDFS:

```bash
hdfs dfs -mkdir /user
hdfs dfs -mkdir /user/hadoop
echo "hola" > ola.txt
hdfs dfs -put ola.txt
hdfs dfs -ls /user/hadoop
```

---

## Persistencia

Los datos del NameNode y DataNode estÃ¡n en volÃºmenes persistentes:

* `namenode_data` â†’ `/home/hadoop/namenode`
* `datanode_data` â†’ `/home/hadoop/datanode`

Para comprobar la persistencia:

```bash
docker-compose down
docker-compose up -d
docker exec namenode hdfs dfs -ls /user/hadoop
```

---

## Parar el clÃºster

```bash
docker-compose down
```

Esto detiene todos los contenedores.

---

## Estructura del proyecto

```
simple-hadoop-cluster/
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ start-dfs.sh
â”œâ”€â”€ conf/
â”‚   â”œâ”€â”€ core-site.xml
â”‚   â”œâ”€â”€ hdfs-site.xml
â”‚   â”œâ”€â”€ mapred-site.xml
â”‚   â””â”€â”€ yarn-site.xml
â””â”€â”€ README.md
```

---

## Autor

ğŸ‘©â€ğŸ’» Tania Paz â€“ [GitHub](https://github.com/tania-commits)

---

## Notas

* El clÃºster estÃ¡ configurado para un solo nodo de prueba (pseudo-distribuido), Ãºtil para aprendizaje y pruebas.
* Se ha configurado SSH sin contraseÃ±a para comunicaciÃ³n entre contenedores.
* Hadoop estÃ¡ configurado para YARN como framework de ejecuciÃ³n de MapReduce.

---

## Comandos de Git para subir el proyecto

Abre PowerShell en la raÃ­z del proyecto y ejecuta:

```powershell
# Inicializar git si no lo estÃ¡
git init

# Asegurarse de que el remoto apunta al repo correcto
git remote set-url origin https://github.com/tania-commits/hadoop-docker-cluster.git

# AÃ±adir todos los archivos
git add .

# Hacer commit
git commit -m "Proyecto completo: ClÃºster Hadoop con Docker, Dockerfile, docker-compose y configuraciÃ³n"

# Asegurar que la rama principal se llama main
git branch -M main

# Subir al repositorio remoto
git push -u origin main
```
